{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6263f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "RANDOM_SEED = 422\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "class Racetrack:\n",
    "    def __init__(self):\n",
    "        self.track = self._create_r_track()\n",
    "        \n",
    "        self.start_line = self._find_start_line()\n",
    "        self.finish_line = self._find_finish_line()\n",
    "    \n",
    "    def _create_r_track(self):\n",
    "        track1 = [\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0],\n",
    "        ]\n",
    "        track2 = [\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0]\n",
    "        ]\n",
    "        return np.array(track1)\n",
    "    \n",
    "    def _find_start_line(self):\n",
    "        starts = []\n",
    "        rows, cols = self.track.shape\n",
    "        for j in range(cols):\n",
    "            if self.track[rows-1, j] == 1:\n",
    "                starts.append((rows-1, j))\n",
    "        return starts\n",
    "    \n",
    "    def _find_finish_line(self):\n",
    "        finishes = []\n",
    "        rows, cols = self.track.shape\n",
    "        for i in range(rows):\n",
    "            if self.track[i, cols-1] == 1:\n",
    "                finishes.append((i, cols-1))\n",
    "        return finishes\n",
    "    \n",
    "    def reset(self):\n",
    "        pos = random.choice(self.start_line)\n",
    "        velocity = (0, 0)\n",
    "        return pos, velocity\n",
    "    \n",
    "    def step(self, state, action):\n",
    "        (y, x), (vy, vx) = state\n",
    "        ay, ax = action\n",
    "        if random.random() < 0.1:\n",
    "            ay, ax = 0, 0\n",
    "        new_vy = max(0, min(4, vy + ay))\n",
    "        new_vx = max(0, min(4, vx + ax))\n",
    "        \n",
    "\n",
    "        if new_vy == 0 and new_vx == 0:\n",
    "            new_vy, new_vx = vy, vx\n",
    "            if new_vy == 0 and new_vx == 0:\n",
    "                new_vx = 1 \n",
    "        \n",
    "\n",
    "        new_y = y - new_vy  \n",
    "        new_x = x + new_vx\n",
    "\n",
    "        crossed_finish, hit_boundary = self._check_trajectory(\n",
    "            (y, x), (new_y, new_x)\n",
    "        )\n",
    "        \n",
    "        if crossed_finish:\n",
    "            return None, -1, True\n",
    "        \n",
    "        if hit_boundary:\n",
    "\n",
    "            pos = random.choice(self.start_line)\n",
    "            return (pos, (0, 0)), -1, False\n",
    "        \n",
    "        return ((new_y, new_x), (new_vy, new_vx)), -1, False\n",
    "    \n",
    "    def _check_trajectory(self, pos1, pos2):\n",
    "        y1, x1 = pos1\n",
    "        y2, x2 = pos2\n",
    "        \n",
    "        points = self._bresenham_line(y1, x1, y2, x2)\n",
    "        \n",
    "        for y, x in points:\n",
    "\n",
    "            if y < 0 or y >= self.track.shape[0] or x < 0 or x >= self.track.shape[1]:\n",
    "                return False, True\n",
    "            \n",
    "\n",
    "            if self.track[y, x] == 0:\n",
    "                return False, True\n",
    "            \n",
    "            if (y, x) in self.finish_line:\n",
    "                return True, False\n",
    "        \n",
    "        return False, False\n",
    "    \n",
    "    def _bresenham_line(self, y1, x1, y2, x2):\n",
    "        points = []\n",
    "        dy = abs(y2 - y1)\n",
    "        dx = abs(x2 - x1)\n",
    "        sy = 1 if y2 > y1 else -1\n",
    "        sx = 1 if x2 > x1 else -1\n",
    "        err = dx - dy\n",
    "        \n",
    "        y, x = y1, x1\n",
    "        \n",
    "        while True:\n",
    "            points.append((y, x))\n",
    "            if y == y2 and x == x2:\n",
    "                break\n",
    "            e2 = 2 * err\n",
    "            if e2 > -dy:\n",
    "                err -= dy\n",
    "                x += sx\n",
    "            if e2 < dx:\n",
    "                err += dx\n",
    "                y += sy\n",
    "        \n",
    "        return points\n",
    "\n",
    "\n",
    "class MonteCarloControl:\n",
    "    def __init__(self, env, epsilon=0.1, gamma=1.0, dynamic = False):\n",
    "        self.env = env\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.dynamic = dynamic\n",
    "        self.Q = defaultdict(lambda: np.zeros(9))  \n",
    "        self.returns = defaultdict(list)\n",
    "        self.policy = defaultdict(lambda: 4) \n",
    "        \n",
    "    def get_actions(self):\n",
    "        return [(ay, ax) for ay in [-1, 0, 1] for ax in [-1, 0, 1]]\n",
    "    \n",
    "    def action_to_index(self, action):\n",
    "        ay, ax = action\n",
    "        return (ay + 1) * 3 + (ax + 1)\n",
    "    \n",
    "    def index_to_action(self, idx):\n",
    "        ay = idx // 3 - 1\n",
    "        ax = idx % 3 - 1\n",
    "        return (ay, ax)\n",
    "    \n",
    "    def epsilon_greedy_policy(self, state,ep):\n",
    "        if self.dynamic:\n",
    "            if random.random() < (self.epsilon)*(1-ep/10000):\n",
    "                return random.choice(self.get_actions())\n",
    "            else:\n",
    "                best_action_idx = np.argmax(self.Q[state])\n",
    "                return self.index_to_action(best_action_idx)    \n",
    "        else:\n",
    "            if random.random() < self.epsilon:\n",
    "                return random.choice(self.get_actions())\n",
    "            else:\n",
    "                best_action_idx = np.argmax(self.Q[state])\n",
    "                return self.index_to_action(best_action_idx)\n",
    "    \n",
    "    def generate_episode(self,ep):\n",
    "        episode = []\n",
    "        pos, vel = self.env.reset()\n",
    "        state = (pos, vel)\n",
    "        \n",
    "        for _ in range(1000):  \n",
    "            action = self.epsilon_greedy_policy(state,ep)\n",
    "            next_state, reward, done = self.env.step(state, action)\n",
    "            \n",
    "            episode.append((state, action, reward))\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            state = next_state\n",
    "        \n",
    "        return episode\n",
    "    \n",
    "    def train(self, num_episodes=10000):\n",
    "        episode_lengths = []\n",
    "        \n",
    "        for ep in range(num_episodes):\n",
    "            episode = self.generate_episode(ep+1)\n",
    "            episode_lengths.append(len(episode))\n",
    "            \n",
    "\n",
    "            visited = set()\n",
    "            G = 0\n",
    "            \n",
    "\n",
    "            for t in range(len(episode) - 1, -1, -1):\n",
    "                state, action, reward = episode[t]\n",
    "                G = self.gamma * G + reward\n",
    "                \n",
    "                state_action = (state, action)\n",
    "                \n",
    "\n",
    "                if state_action not in visited:\n",
    "                    visited.add(state_action)\n",
    "                    action_idx = self.action_to_index(action)\n",
    "                    self.returns[state_action].append(G)\n",
    "                    self.Q[state][action_idx] = np.mean(self.returns[state_action])\n",
    "\n",
    "                    best_action_idx = np.argmax(self.Q[state])\n",
    "                    self.policy[state] = best_action_idx\n",
    "\n",
    "        \n",
    "        return episode_lengths\n",
    "    \n",
    "    def get_optimal_trajectory(self, max_steps=100):\n",
    "        pos, vel = self.env.reset()\n",
    "        state = (pos, vel)\n",
    "        trajectory = [pos]\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            best_action_idx = np.argmax(self.Q[state])\n",
    "            action = self.index_to_action(best_action_idx)\n",
    "            \n",
    "            next_state, reward, done = self.env.step(state, action)\n",
    "            \n",
    "            if done:\n",
    "                trajectory.append(self.env.finish_line[0])\n",
    "                break\n",
    "            \n",
    "            if next_state is None:\n",
    "                break\n",
    "                \n",
    "            trajectory.append(next_state[0])\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "\n",
    "def main():\n",
    "    env_l = Racetrack()\n",
    "    agent_l = MonteCarloControl(env_l, epsilon=0, gamma=1.0)\n",
    "    agent_dy = MonteCarloControl(env_l, epsilon=0.1, gamma=1.0,dynamic=True)\n",
    "    lengths_l = agent_l.train(num_episodes=10000)\n",
    "    lengths_dy = agent_dy.train(num_episodes=10000)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "\n",
    "    window_size = 100\n",
    "    moving_avg = np.convolve(lengths_l, np.ones(window_size)/window_size, mode='valid')\n",
    "    axes[0].plot(range(window_size-1, len(lengths_l)), moving_avg, linewidth=2,c='b',alpha = 0.5,label=\"constant epsilon\")\n",
    "    moving_avg_dy = np.convolve(lengths_dy, np.ones(window_size)/window_size, mode='valid')\n",
    "    axes[0].plot(range(window_size-1, len(lengths_dy)), moving_avg_dy, linewidth=2,c='r',alpha = 0.5,label=\"dynamic epsilon\")\n",
    "    axes[0].set_xlabel('Episode')\n",
    "    axes[0].set_ylabel('Average Episode Length')\n",
    "    axes[0].set_title(f'Learning Curve (RaceTrack, {window_size}-Episode Moving Average)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend()\n",
    "\n",
    "    track = env_l.track\n",
    "    axes[1].set_xlim(-0.5, track.shape[1] - 0.5)\n",
    "    axes[1].set_ylim(-0.5, track.shape[0] - 0.5) \n",
    "    axes[1].set_aspect('equal')\n",
    "    axes[1].set_title('RaceTrack with Optimal Trajectory')\n",
    "    axes[1].set_facecolor('white')\n",
    "    \n",
    "\n",
    "    for i in range(track.shape[0]):\n",
    "        for j in range(track.shape[1]):\n",
    "            if track[i, j] == 1: \n",
    "                y_flipped = track.shape[0] - 1 - i\n",
    "                rect = plt.Rectangle((j-0.5, y_flipped-0.5), 1, 1, \n",
    "                                    linewidth=0.5, edgecolor='lightgray', \n",
    "                                    facecolor='none')\n",
    "                axes[1].add_patch(rect)\n",
    "    \n",
    "\n",
    "    for i in range(track.shape[0]):\n",
    "        for j in range(track.shape[1]):\n",
    "            if track[i, j] == 1: \n",
    "                y_flipped = track.shape[0] - 1 - i\n",
    "\n",
    "                if j == track.shape[1] - 1 or track[i, j+1] == 0:\n",
    "                    axes[1].plot([j+0.5, j+0.5], [y_flipped-0.5, y_flipped+0.5], 'k-', linewidth=2)\n",
    "\n",
    "                if j == 0 or track[i, j-1] == 0:\n",
    "                    axes[1].plot([j-0.5, j-0.5], [y_flipped-0.5, y_flipped+0.5], 'k-', linewidth=2)\n",
    "\n",
    "                if i == track.shape[0] - 1 or track[i+1, j] == 0:\n",
    "                    axes[1].plot([j-0.5, j+0.5], [y_flipped-0.5, y_flipped-0.5], 'k-', linewidth=2)\n",
    "\n",
    "                if i == 0 or track[i-1, j] == 0:\n",
    "                    axes[1].plot([j-0.5, j+0.5], [y_flipped+0.5, y_flipped+0.5], 'k-', linewidth=2)\n",
    "\n",
    "    start_ys = [track.shape[0] - 1 - p[0] for p in env_l.start_line]\n",
    "    start_xs = [p[1] for p in env_l.start_line]\n",
    "    axes[1].plot(start_xs, start_ys, 'r-', linewidth=4, label='Start Line')\n",
    "    \n",
    "    finish_ys = [track.shape[0] - 1 - p[0] for p in env_l.finish_line]\n",
    "    finish_xs = [p[1] for p in env_l.finish_line]\n",
    "    axes[1].plot(finish_xs, finish_ys, 'g-', linewidth=4, label='Finish Line')\n",
    "    \n",
    "    colors = ['blue', 'purple', 'orange']\n",
    "    for i in range(3):\n",
    "        trajectory = agent_l.get_optimal_trajectory()\n",
    "        ys = [track.shape[0] - 1 - p[0] for p in trajectory]\n",
    "        xs = [p[1] for p in trajectory]\n",
    "        axes[1].plot(xs, ys, '-o', color=colors[i], markersize=3, \n",
    "                    linewidth=2, alpha=0.7, label=f'Trajectory {i+1}')\n",
    "    \n",
    "    axes[1].set_xlabel('X Position')\n",
    "    axes[1].set_ylabel('Y Position')\n",
    "    axes[1].legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_25s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
